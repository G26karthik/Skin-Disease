# Supplementary PBL Report — Skin Disease AI Decision Support

This supplementary report collates the project's codebase findings, key metrics, and visual artifacts for academic review. It references the generated images in `docs/images/` produced during training and evaluation.

---

## 1. Executive Summary

This project trains an EfficientNet_B0-based classifier on the HAM10000 dermatoscopic dataset to classify 7 lesion types. The full training run (30 epochs on combined train+validation) produced a test accuracy of 85.77% and macro F1 of 75.12%. The system provides Grad-CAM visual explanations, calibration metrics (ECE, Brier), and inference profiling (latency and throughput). See the Results section for per-class numbers and artifact references.

---

## 2. Key Visual Artifacts

- Architecture diagram: `docs/images/architecture.png`
- Class distribution: `docs/images/class_distribution.png`
- Grad-CAM montage (examples): `docs/images/gradcam_montage.png`
- Confusion matrix (normalized): `docs/images/confusion_matrix.png`
- Reliability (calibration) diagram: `docs/images/reliability.png`
- Training curves: `docs/images/training_curves.png`
- Per-class metrics plot: `docs/images/per_class_metrics.png`
- Latency profile: `docs/images/latency.png`
- Roadmap: `docs/images/roadmap.png`

(These images are generated by `scripts/generate_report_figures.py` using artifacts in `runs/` and `models/`.)

### Sample Test Images (one per class)

Below are real dermatoscopic samples taken from the HAM10000 test set (copied into the repository under `docs/images/samples/`). These are representative images used for manual inspection and illustrative Grad-CAM overlays.

- Actinic keratoses: `docs/images/samples/actinic_keratoses.jpg`
- Basal cell carcinoma: `docs/images/samples/basal_cell_carcinoma.jpg`
- Benign keratosis: `docs/images/samples/benign_keratosis.jpg`
- Dermatofibroma: `docs/images/samples/dermatofibroma.jpg`
- Melanoma: `docs/images/samples/melanoma.jpg`
- Melanocytic nevi: `docs/images/samples/melanocytic_nevi.jpg`
- Vascular lesions: `docs/images/samples/vascular_lesions.jpg`

---

## 3. Final Metrics (from `runs/test_eval_metrics.json`)

- Test Accuracy: 0.8577154308617234 (≈ 85.77%)
- Macro Precision: 0.7710219076669106
- Macro Recall: 0.7395027738947345
- Macro F1: 0.7512110404245183 (≈ 75.12%)
- Weighted F1: 0.8555148080462415
- ECE (expected calibration error): 0.0450 (reported)
- Brier Score: 0.2764 (reported)
- Mean Inference Latency: 0.00629 s (≈ 6.29 ms)
- Throughput: 158.89 images/s

### Per-class (precision / recall / f1 / support)
- Actinic_keratoses: precision 0.6667, recall 0.62745, f1 0.64646, support 102
- Basal_cell_carcinoma: precision 0.75342, recall 0.71429, f1 0.73333, support 154
- Benign_keratosis: precision 0.74667, recall 0.71338, f1 0.72964, support 314
- Dermatofibroma: precision 0.60714, recall 0.77273, f1 0.68000, support 44
- Melanoma: precision 0.70667, recall 0.63095, f1 0.66667, support 336
- Melanocytic_nevi: precision 0.91659, recall 0.94500, f1 0.93058, support 2000
- Vascular_lesions: precision 1.00000, recall 0.77273, f1 0.87179, support 44

(Per-class values were read from `runs/test_eval_metrics.json`.)

---

## 4. How to Reproduce Key Artifacts

1. Train the model (example):

```powershell
python -m src.train --data_dir data --epochs 30 --batch_size 32
```

2. Generate report-quality figures (after training):

```powershell
python scripts/generate_report_figures.py
```

3. Run the Streamlit demo (after saving the model to `models/model.pt`):

```powershell
streamlit run app.py
```

---

## 5. Notes and Next Steps

- Calibration: run temperature scaling script (planned) to reduce ECE further.
- Minority-class performance: consider class-balanced losses, augmentation, and external datasets for melanoma sensitivity improvement.
- External validation: evaluate on independent datasets to estimate generalization and fairness across skin tones.

---

## 6. Artifacts Location

- Model weights and checkpoints: `models/`
- Confusion matrix: `models/confusion_matrix.npy`
- Run metrics and history: `runs/` (includes `test_eval_metrics.json`, `history.json`, `last_run.json`)
- Figures used in this document: `docs/images/`

---

*Generated from repository artifacts on October 29, 2025.*
